{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53160f2d",
   "metadata": {
    "id": "53160f2d"
   },
   "source": [
    "## NEURAL NETWORKS AND DEEP LEARNING\n",
    "### Time Series\n",
    "### Name:\n",
    "### Course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19750a1a",
   "metadata": {
    "id": "19750a1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:59:44.483390: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 00:59:45.483674: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 00:59:45.483716: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 00:59:45.488216: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 00:59:45.939796: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 00:59:45.942920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 00:59:47.964496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fcc827",
   "metadata": {
    "id": "d6fcc827"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_df = pd.read_csv('lsst-train.csv')\n",
    "test_df = pd.read_csv('lsst-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ab2c15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "d4ab2c15",
    "outputId": "c3b4a4e1-26d3-4700-e8b6-01c3bcbc2d66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f-1-1</th>\n",
       "      <th>f-1-2</th>\n",
       "      <th>f-1-3</th>\n",
       "      <th>f-1-4</th>\n",
       "      <th>f-1-5</th>\n",
       "      <th>f-1-6</th>\n",
       "      <th>f-1-7</th>\n",
       "      <th>f-1-8</th>\n",
       "      <th>f-1-9</th>\n",
       "      <th>f-1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>f-6-28</th>\n",
       "      <th>f-6-29</th>\n",
       "      <th>f-6-30</th>\n",
       "      <th>f-6-31</th>\n",
       "      <th>f-6-32</th>\n",
       "      <th>f-6-33</th>\n",
       "      <th>f-6-34</th>\n",
       "      <th>f-6-35</th>\n",
       "      <th>f-6-36</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.57770</td>\n",
       "      <td>-1.18830</td>\n",
       "      <td>-4.98950</td>\n",
       "      <td>-6.4301</td>\n",
       "      <td>-4.6503</td>\n",
       "      <td>-1.02450</td>\n",
       "      <td>1.90420</td>\n",
       "      <td>2.48850</td>\n",
       "      <td>1.360500</td>\n",
       "      <td>0.90286</td>\n",
       "      <td>...</td>\n",
       "      <td>22.36600</td>\n",
       "      <td>-24.7480</td>\n",
       "      <td>-34.21500</td>\n",
       "      <td>7.7464</td>\n",
       "      <td>-5.8332</td>\n",
       "      <td>-0.71757</td>\n",
       "      <td>8.16160</td>\n",
       "      <td>-29.6940</td>\n",
       "      <td>-27.5700</td>\n",
       "      <td>c-90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.67580</td>\n",
       "      <td>22.54300</td>\n",
       "      <td>44.02700</td>\n",
       "      <td>66.9610</td>\n",
       "      <td>86.0820</td>\n",
       "      <td>96.80400</td>\n",
       "      <td>96.76000</td>\n",
       "      <td>86.49400</td>\n",
       "      <td>69.094000</td>\n",
       "      <td>48.97100</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26700</td>\n",
       "      <td>28.5110</td>\n",
       "      <td>0.97578</td>\n",
       "      <td>-28.0270</td>\n",
       "      <td>-18.0720</td>\n",
       "      <td>-4.00020</td>\n",
       "      <td>-43.07500</td>\n",
       "      <td>-4.7283</td>\n",
       "      <td>-43.0070</td>\n",
       "      <td>c-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.37554</td>\n",
       "      <td>-3.10860</td>\n",
       "      <td>-0.26009</td>\n",
       "      <td>3.2281</td>\n",
       "      <td>-1.9951</td>\n",
       "      <td>0.12797</td>\n",
       "      <td>0.25844</td>\n",
       "      <td>-0.25394</td>\n",
       "      <td>-0.091828</td>\n",
       "      <td>2.41440</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.02610</td>\n",
       "      <td>14.5270</td>\n",
       "      <td>50.00500</td>\n",
       "      <td>-13.8860</td>\n",
       "      <td>3.3589</td>\n",
       "      <td>5.00450</td>\n",
       "      <td>-0.47256</td>\n",
       "      <td>-2.7713</td>\n",
       "      <td>1.9379</td>\n",
       "      <td>c-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.51852</td>\n",
       "      <td>0.12078</td>\n",
       "      <td>1.53240</td>\n",
       "      <td>5.5783</td>\n",
       "      <td>11.5340</td>\n",
       "      <td>17.01300</td>\n",
       "      <td>18.97100</td>\n",
       "      <td>15.38700</td>\n",
       "      <td>6.685500</td>\n",
       "      <td>-4.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>23.24700</td>\n",
       "      <td>31.9850</td>\n",
       "      <td>26.62100</td>\n",
       "      <td>-12.2560</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>23.80500</td>\n",
       "      <td>-32.36400</td>\n",
       "      <td>-15.1610</td>\n",
       "      <td>-14.4500</td>\n",
       "      <td>c-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.47150</td>\n",
       "      <td>1.44510</td>\n",
       "      <td>2.91330</td>\n",
       "      <td>1.0015</td>\n",
       "      <td>-1.2503</td>\n",
       "      <td>1.55160</td>\n",
       "      <td>1.73170</td>\n",
       "      <td>0.47796</td>\n",
       "      <td>0.539860</td>\n",
       "      <td>-1.71690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18477</td>\n",
       "      <td>3.8533</td>\n",
       "      <td>-5.80000</td>\n",
       "      <td>1.4909</td>\n",
       "      <td>2.7581</td>\n",
       "      <td>-3.16650</td>\n",
       "      <td>-0.30058</td>\n",
       "      <td>6.6334</td>\n",
       "      <td>7.3427</td>\n",
       "      <td>c-67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f-1-1     f-1-2     f-1-3    f-1-4    f-1-5     f-1-6     f-1-7  \\\n",
       "0  2.57770  -1.18830  -4.98950  -6.4301  -4.6503  -1.02450   1.90420   \n",
       "1  6.67580  22.54300  44.02700  66.9610  86.0820  96.80400  96.76000   \n",
       "2  0.37554  -3.10860  -0.26009   3.2281  -1.9951   0.12797   0.25844   \n",
       "3  0.51852   0.12078   1.53240   5.5783  11.5340  17.01300  18.97100   \n",
       "4  1.47150   1.44510   2.91330   1.0015  -1.2503   1.55160   1.73170   \n",
       "\n",
       "      f-1-8      f-1-9    f-1-10  ...    f-6-28   f-6-29    f-6-30   f-6-31  \\\n",
       "0   2.48850   1.360500   0.90286  ...  22.36600 -24.7480 -34.21500   7.7464   \n",
       "1  86.49400  69.094000  48.97100  ...  19.26700  28.5110   0.97578 -28.0270   \n",
       "2  -0.25394  -0.091828   2.41440  ...  -4.02610  14.5270  50.00500 -13.8860   \n",
       "3  15.38700   6.685500  -4.07800  ...  23.24700  31.9850  26.62100 -12.2560   \n",
       "4   0.47796   0.539860  -1.71690  ...  -0.18477   3.8533  -5.80000   1.4909   \n",
       "\n",
       "    f-6-32    f-6-33    f-6-34   f-6-35   f-6-36  target  \n",
       "0  -5.8332  -0.71757   8.16160 -29.6940 -27.5700    c-90  \n",
       "1 -18.0720  -4.00020 -43.07500  -4.7283 -43.0070    c-15  \n",
       "2   3.3589   5.00450  -0.47256  -2.7713   1.9379    c-42  \n",
       "3   3.4805  23.80500 -32.36400 -15.1610 -14.4500    c-16  \n",
       "4   2.7581  -3.16650  -0.30058   6.6334   7.3427    c-67  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e7d90e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "76e7d90e",
    "outputId": "d4e11e63-ab91-4490-ff76-c7e2cfd2dcc0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f-1-1</th>\n",
       "      <th>f-1-2</th>\n",
       "      <th>f-1-3</th>\n",
       "      <th>f-1-4</th>\n",
       "      <th>f-1-5</th>\n",
       "      <th>f-1-6</th>\n",
       "      <th>f-1-7</th>\n",
       "      <th>f-1-8</th>\n",
       "      <th>f-1-9</th>\n",
       "      <th>f-1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>f-6-27</th>\n",
       "      <th>f-6-28</th>\n",
       "      <th>f-6-29</th>\n",
       "      <th>f-6-30</th>\n",
       "      <th>f-6-31</th>\n",
       "      <th>f-6-32</th>\n",
       "      <th>f-6-33</th>\n",
       "      <th>f-6-34</th>\n",
       "      <th>f-6-35</th>\n",
       "      <th>f-6-36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.575000</td>\n",
       "      <td>25.5650</td>\n",
       "      <td>6.8052</td>\n",
       "      <td>-26.012</td>\n",
       "      <td>-55.1290</td>\n",
       "      <td>-62.0750</td>\n",
       "      <td>-43.3400</td>\n",
       "      <td>-14.26500</td>\n",
       "      <td>4.03600</td>\n",
       "      <td>2.8128</td>\n",
       "      <td>...</td>\n",
       "      <td>114.9600</td>\n",
       "      <td>116.3700</td>\n",
       "      <td>69.0540</td>\n",
       "      <td>11.8250</td>\n",
       "      <td>29.5960</td>\n",
       "      <td>55.14500</td>\n",
       "      <td>1.0701</td>\n",
       "      <td>-31.4420</td>\n",
       "      <td>20.914</td>\n",
       "      <td>39.9590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.432400</td>\n",
       "      <td>10.4920</td>\n",
       "      <td>16.6900</td>\n",
       "      <td>14.609</td>\n",
       "      <td>3.8112</td>\n",
       "      <td>-8.9224</td>\n",
       "      <td>-15.1370</td>\n",
       "      <td>-11.82400</td>\n",
       "      <td>-3.60240</td>\n",
       "      <td>2.0792</td>\n",
       "      <td>...</td>\n",
       "      <td>16.7950</td>\n",
       "      <td>3.3646</td>\n",
       "      <td>5.7902</td>\n",
       "      <td>52.7540</td>\n",
       "      <td>-19.5210</td>\n",
       "      <td>-9.35210</td>\n",
       "      <td>63.4920</td>\n",
       "      <td>-17.8800</td>\n",
       "      <td>-40.938</td>\n",
       "      <td>6.2865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.166710</td>\n",
       "      <td>-1.0756</td>\n",
       "      <td>-0.8531</td>\n",
       "      <td>1.626</td>\n",
       "      <td>-1.8959</td>\n",
       "      <td>2.4717</td>\n",
       "      <td>-0.2629</td>\n",
       "      <td>-1.43750</td>\n",
       "      <td>0.89766</td>\n",
       "      <td>-2.4570</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3971</td>\n",
       "      <td>-8.2973</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>-3.6586</td>\n",
       "      <td>-6.4716</td>\n",
       "      <td>0.87079</td>\n",
       "      <td>2.6530</td>\n",
       "      <td>2.2138</td>\n",
       "      <td>-1.323</td>\n",
       "      <td>-2.1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.800300</td>\n",
       "      <td>-3.5558</td>\n",
       "      <td>-5.2497</td>\n",
       "      <td>-10.011</td>\n",
       "      <td>-10.9800</td>\n",
       "      <td>-3.5785</td>\n",
       "      <td>4.9622</td>\n",
       "      <td>2.28200</td>\n",
       "      <td>-11.07200</td>\n",
       "      <td>-17.1180</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9662</td>\n",
       "      <td>-6.1161</td>\n",
       "      <td>-34.6170</td>\n",
       "      <td>-96.5080</td>\n",
       "      <td>-94.9050</td>\n",
       "      <td>-8.84960</td>\n",
       "      <td>48.7190</td>\n",
       "      <td>-15.2810</td>\n",
       "      <td>-15.786</td>\n",
       "      <td>34.8360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.048579</td>\n",
       "      <td>-11.9320</td>\n",
       "      <td>-25.6890</td>\n",
       "      <td>-35.259</td>\n",
       "      <td>-36.0600</td>\n",
       "      <td>-27.6460</td>\n",
       "      <td>-13.9240</td>\n",
       "      <td>-0.79703</td>\n",
       "      <td>7.31190</td>\n",
       "      <td>9.8219</td>\n",
       "      <td>...</td>\n",
       "      <td>63.1690</td>\n",
       "      <td>64.7760</td>\n",
       "      <td>53.0120</td>\n",
       "      <td>-83.1160</td>\n",
       "      <td>-50.6480</td>\n",
       "      <td>79.74300</td>\n",
       "      <td>-16.5700</td>\n",
       "      <td>74.2040</td>\n",
       "      <td>72.036</td>\n",
       "      <td>100.2200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f-1-1    f-1-2    f-1-3   f-1-4    f-1-5    f-1-6    f-1-7     f-1-8  \\\n",
       "0  25.575000  25.5650   6.8052 -26.012 -55.1290 -62.0750 -43.3400 -14.26500   \n",
       "1   2.432400  10.4920  16.6900  14.609   3.8112  -8.9224 -15.1370 -11.82400   \n",
       "2  -0.166710  -1.0756  -0.8531   1.626  -1.8959   2.4717  -0.2629  -1.43750   \n",
       "3  -4.800300  -3.5558  -5.2497 -10.011 -10.9800  -3.5785   4.9622   2.28200   \n",
       "4  -0.048579 -11.9320 -25.6890 -35.259 -36.0600 -27.6460 -13.9240  -0.79703   \n",
       "\n",
       "      f-1-9   f-1-10  ...    f-6-27    f-6-28   f-6-29   f-6-30   f-6-31  \\\n",
       "0   4.03600   2.8128  ...  114.9600  116.3700  69.0540  11.8250  29.5960   \n",
       "1  -3.60240   2.0792  ...   16.7950    3.3646   5.7902  52.7540 -19.5210   \n",
       "2   0.89766  -2.4570  ...   -3.3971   -8.2973   8.8071  -3.6586  -6.4716   \n",
       "3 -11.07200 -17.1180  ...    2.9662   -6.1161 -34.6170 -96.5080 -94.9050   \n",
       "4   7.31190   9.8219  ...   63.1690   64.7760  53.0120 -83.1160 -50.6480   \n",
       "\n",
       "     f-6-32   f-6-33   f-6-34  f-6-35    f-6-36  \n",
       "0  55.14500   1.0701 -31.4420  20.914   39.9590  \n",
       "1  -9.35210  63.4920 -17.8800 -40.938    6.2865  \n",
       "2   0.87079   2.6530   2.2138  -1.323   -2.1806  \n",
       "3  -8.84960  48.7190 -15.2810 -15.786   34.8360  \n",
       "4  79.74300 -16.5700  74.2040  72.036  100.2200  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deeca56d",
   "metadata": {
    "id": "deeca56d"
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "# Convert the target column to categorical integer labels\n",
    "class_mapping = {label: idx for idx, label in enumerate(train_df['target'].unique())}\n",
    "train_df['target'] = train_df['target'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3c1de4",
   "metadata": {
    "id": "6b3c1de4"
   },
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = train_df.drop('target', axis=1).values\n",
    "y_train = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "364dd558",
   "metadata": {
    "id": "364dd558"
   },
   "outputs": [],
   "source": [
    "# Reshape for the model input\n",
    "X_train_reshaped = X_train.reshape((-1, 6, 36))\n",
    "X_test = test_df.values\n",
    "X_test_reshaped = X_test.reshape((-1, 6, 36))\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "# Adapt the normalizer with the correct reshaped data\n",
    "normalizer.adapt(X_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c55bc72",
   "metadata": {
    "id": "1c55bc72"
   },
   "outputs": [],
   "source": [
    "input_shape = X_train_reshaped.shape[1:]\n",
    "num_classes = len(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1d5aa4",
   "metadata": {
    "id": "6a1d5aa4"
   },
   "outputs": [],
   "source": [
    "# Adapt the normalizer to the reshaped data\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X_train_reshaped)\n",
    "\n",
    "# Model 1: LSTM with Dropout\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27cee5e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27cee5e9",
    "outputId": "cbe52144-638a-455f-ebfb-73d09a96d4ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_1 = model_1.fit(X_train_reshaped, y_train, epochs=50, batch_size=64, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "predictions_1 = model_1.predict(X_test_reshaped)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission_df_1 = pd.DataFrame(predictions_1, columns=['class_' + str(i) for i in range(num_classes)])\n",
    "submission_df_1.insert(0, 'object_id', test_df.index)\n",
    "submission_df_1.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "001fd3b3",
   "metadata": {
    "id": "001fd3b3"
   },
   "outputs": [],
   "source": [
    "# Model 2: More layers, more dropouts\n",
    "model_2 = tf.keras.models.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77438235",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77438235",
    "outputId": "dbac070e-605d-47b1-e96d-2df19160c7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_2 = model_2.fit(X_train_reshaped, y_train, epochs=50, batch_size=64, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "predictions_2 = model_2.predict(X_test_reshaped)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission_df_2 = pd.DataFrame(predictions_2, columns=['class_' + str(i) for i in range(num_classes)])\n",
    "submission_df_2.insert(0, 'object_id', test_df.index)\n",
    "submission_df_2.to_csv('submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89291502",
   "metadata": {
    "id": "89291502"
   },
   "outputs": [],
   "source": [
    "# Model 3: GRU with BatchNormalization\n",
    "model_3 = tf.keras.models.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.GRU(64, return_sequences=True),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.GRU(32),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "981ec384",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "981ec384",
    "outputId": "a8999178-9058-4b09-85f7-27e42a637851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_3 = model_3.fit(X_train_reshaped, y_train, epochs=50, batch_size=64, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "predictions_3 = model_3.predict(X_test_reshaped)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission_df_3 = pd.DataFrame(predictions_3, columns=['class_' + str(i) for i in range(num_classes)])\n",
    "submission_df_3.insert(0, 'object_id', test_df.index)\n",
    "submission_df_3.to_csv('submission_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4abd29f",
   "metadata": {
    "id": "d4abd29f"
   },
   "outputs": [],
   "source": [
    "# Model 4: Bidirectional LSTM\n",
    "model_4 = tf.keras.models.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model_4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cae2898",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cae2898",
    "outputId": "89f34616-4d7e-4665-daa5-bc2db3492533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_4 = model_4.fit(X_train_reshaped, y_train, epochs=50, batch_size=64, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "predictions_4 = model_4.predict(X_test_reshaped)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission_df_4 = pd.DataFrame(predictions_4, columns=['class_' + str(i) for i in range(num_classes)])\n",
    "submission_df_4.insert(0, 'object_id', test_df.index)\n",
    "submission_df_4.to_csv('submission_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b531ce14",
   "metadata": {
    "id": "b531ce14"
   },
   "outputs": [],
   "source": [
    "# Model 5: Convolutional Neural Network and LSTM\n",
    "model_5 = tf.keras.models.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model_5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b08e50d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b08e50d6",
    "outputId": "cab5b013-e4f8-475d-a1fb-35722142ce7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_5 = model_5.fit(X_train_reshaped, y_train, epochs=50, batch_size=64, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "predictions_5 = model_5.predict(X_test_reshaped)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission_df_5 = pd.DataFrame(predictions_5, columns=['class_' + str(i) for i in range(num_classes)])\n",
    "submission_df_5.insert(0, 'object_id', test_df.index)\n",
    "submission_df_5.to_csv('submission_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eZ-sHC8luRO7",
   "metadata": {
    "id": "eZ-sHC8luRO7"
   },
   "source": [
    "Checking the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "GpGsQYNZuQv4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GpGsQYNZuQv4",
    "outputId": "628bd527-e8eb-4254-f211-906fc42ae058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.1456 - accuracy: 0.6125 - val_loss: 1.4296 - val_accuracy: 0.5521\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1488 - accuracy: 0.6103 - val_loss: 1.4308 - val_accuracy: 0.5402\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.1490 - accuracy: 0.6077 - val_loss: 1.4211 - val_accuracy: 0.5461\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1370 - accuracy: 0.6148 - val_loss: 1.4159 - val_accuracy: 0.5476\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.1311 - accuracy: 0.6129 - val_loss: 1.4344 - val_accuracy: 0.5298\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.1329 - accuracy: 0.6140 - val_loss: 1.4233 - val_accuracy: 0.5208\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.1309 - accuracy: 0.6107 - val_loss: 1.4099 - val_accuracy: 0.5521\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.1118 - accuracy: 0.6211 - val_loss: 1.4231 - val_accuracy: 0.5223\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1.1082 - accuracy: 0.6241 - val_loss: 1.4202 - val_accuracy: 0.5357\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1025 - accuracy: 0.6256 - val_loss: 1.4156 - val_accuracy: 0.5372\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0960 - accuracy: 0.6304 - val_loss: 1.3948 - val_accuracy: 0.5446\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.0835 - accuracy: 0.6352 - val_loss: 1.4163 - val_accuracy: 0.5268\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0893 - accuracy: 0.6256 - val_loss: 1.4003 - val_accuracy: 0.5283\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.0778 - accuracy: 0.6319 - val_loss: 1.3819 - val_accuracy: 0.5432\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.0811 - accuracy: 0.6289 - val_loss: 1.4092 - val_accuracy: 0.5268\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.0830 - accuracy: 0.6285 - val_loss: 1.3884 - val_accuracy: 0.5417\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0629 - accuracy: 0.6438 - val_loss: 1.3930 - val_accuracy: 0.5432\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0557 - accuracy: 0.6367 - val_loss: 1.3905 - val_accuracy: 0.5253\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0609 - accuracy: 0.6304 - val_loss: 1.3664 - val_accuracy: 0.5476\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0497 - accuracy: 0.6434 - val_loss: 1.3818 - val_accuracy: 0.5372\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0472 - accuracy: 0.6438 - val_loss: 1.3751 - val_accuracy: 0.5461\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0340 - accuracy: 0.6531 - val_loss: 1.3895 - val_accuracy: 0.5565\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0294 - accuracy: 0.6472 - val_loss: 1.3751 - val_accuracy: 0.5640\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0329 - accuracy: 0.6528 - val_loss: 1.3660 - val_accuracy: 0.5640\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0319 - accuracy: 0.6457 - val_loss: 1.3892 - val_accuracy: 0.5506\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.0173 - accuracy: 0.6531 - val_loss: 1.3703 - val_accuracy: 0.5625\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0089 - accuracy: 0.6621 - val_loss: 1.3923 - val_accuracy: 0.5283\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.0112 - accuracy: 0.6572 - val_loss: 1.3470 - val_accuracy: 0.5714\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.9997 - accuracy: 0.6654 - val_loss: 1.3832 - val_accuracy: 0.5551\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.9997 - accuracy: 0.6561 - val_loss: 1.3609 - val_accuracy: 0.5461\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0089 - accuracy: 0.6606 - val_loss: 1.3555 - val_accuracy: 0.5610\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9998 - accuracy: 0.6662 - val_loss: 1.3653 - val_accuracy: 0.5342\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.9935 - accuracy: 0.6673 - val_loss: 1.3446 - val_accuracy: 0.5551\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.9864 - accuracy: 0.6665 - val_loss: 1.3617 - val_accuracy: 0.5670\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9782 - accuracy: 0.6647 - val_loss: 1.3624 - val_accuracy: 0.5551\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9764 - accuracy: 0.6699 - val_loss: 1.3526 - val_accuracy: 0.5476\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.9711 - accuracy: 0.6740 - val_loss: 1.4358 - val_accuracy: 0.5193\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9685 - accuracy: 0.6732 - val_loss: 1.3581 - val_accuracy: 0.5551\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9829 - accuracy: 0.6651 - val_loss: 1.3488 - val_accuracy: 0.5685\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9782 - accuracy: 0.6714 - val_loss: 1.3775 - val_accuracy: 0.5446\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9716 - accuracy: 0.6759 - val_loss: 1.3768 - val_accuracy: 0.5565\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9672 - accuracy: 0.6725 - val_loss: 1.3544 - val_accuracy: 0.5625\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9786 - accuracy: 0.6602 - val_loss: 1.3513 - val_accuracy: 0.5536\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9538 - accuracy: 0.6796 - val_loss: 1.3664 - val_accuracy: 0.5476\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9332 - accuracy: 0.6755 - val_loss: 1.3116 - val_accuracy: 0.5595\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.9119 - accuracy: 0.6878 - val_loss: 1.2855 - val_accuracy: 0.5774\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9034 - accuracy: 0.6919 - val_loss: 1.3170 - val_accuracy: 0.5461\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.8888 - accuracy: 0.7031 - val_loss: 1.2952 - val_accuracy: 0.5685\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.8941 - accuracy: 0.6893 - val_loss: 1.4619 - val_accuracy: 0.4970\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.8847 - accuracy: 0.7019 - val_loss: 1.4604 - val_accuracy: 0.5387\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.8656 - accuracy: 0.7116 - val_loss: 1.4021 - val_accuracy: 0.5387\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9423 - accuracy: 0.6822 - val_loss: 1.4761 - val_accuracy: 0.5193\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9285 - accuracy: 0.6859 - val_loss: 1.4417 - val_accuracy: 0.5417\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9307 - accuracy: 0.6867 - val_loss: 1.4457 - val_accuracy: 0.5551\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9138 - accuracy: 0.6982 - val_loss: 1.4455 - val_accuracy: 0.5193\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9028 - accuracy: 0.6945 - val_loss: 1.4753 - val_accuracy: 0.5268\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.9073 - accuracy: 0.6967 - val_loss: 1.4703 - val_accuracy: 0.5074\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.8970 - accuracy: 0.7019 - val_loss: 1.4662 - val_accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.6572 - accuracy: 0.7779 - val_loss: 1.3105 - val_accuracy: 0.6027\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6603 - accuracy: 0.7921 - val_loss: 1.3260 - val_accuracy: 0.5685\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6249 - accuracy: 0.7966 - val_loss: 1.2722 - val_accuracy: 0.6116\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6103 - accuracy: 0.8066 - val_loss: 1.2687 - val_accuracy: 0.6116\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5941 - accuracy: 0.8089 - val_loss: 1.2879 - val_accuracy: 0.6146\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.6032 - accuracy: 0.8055 - val_loss: 1.2843 - val_accuracy: 0.6012\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.5751 - accuracy: 0.8174 - val_loss: 1.3048 - val_accuracy: 0.6116\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.5588 - accuracy: 0.8256 - val_loss: 1.3074 - val_accuracy: 0.5952\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5508 - accuracy: 0.8297 - val_loss: 1.3770 - val_accuracy: 0.5893\n",
      "[{'model': 'model_5', 'val_accuracy': 0.6145833134651184, 'val_loss': 1.2687368392944336}, {'model': 'model_3', 'val_accuracy': 0.5773809552192688, 'val_loss': 1.2855219841003418}, {'model': 'model_1', 'val_accuracy': 0.5714285969734192, 'val_loss': 1.3445675373077393}, {'model': 'model_2', 'val_accuracy': 0.5684523582458496, 'val_loss': 1.3487677574157715}, {'model': 'model_4', 'val_accuracy': 0.555059552192688, 'val_loss': 1.4416824579238892}]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define an EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train each model and store the validation performance\n",
    "validation_results = []\n",
    "models = [model_1, model_1, model_3, model_4, model_5]\n",
    "for i, model in enumerate (models):\n",
    "    history = model.fit(\n",
    "        X_train_reshaped,\n",
    "        y_train,\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1  # Set to 0 for no output, 1 for progress bar, 2 for one line per epoch\n",
    "    )\n",
    "    validation_results.append({\n",
    "        'model': f'model_{i+1}',\n",
    "        'val_accuracy': max(history.history['val_accuracy']),\n",
    "        'val_loss': min(history.history['val_loss'])\n",
    "    })\n",
    "\n",
    "# Sort the models based on validation accuracy or loss\n",
    "best_models = sorted(validation_results, key=lambda x: x['val_accuracy'], reverse=True)\n",
    "print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d0ca056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model  val_accuracy  val_loss\n",
      "0  Model 1          0.55      1.35\n",
      "1  Model 2          0.57      1.33\n",
      "2  Model 3          0.58      1.30\n",
      "3  Model 4          0.56      1.34\n",
      "4  Model 5          0.60      1.28\n"
     ]
    }
   ],
   "source": [
    "histories = [\n",
    "    {'model': 'Model 1', 'val_accuracy': 0.55, 'val_loss': 1.35},\n",
    "    {'model': 'Model 2', 'val_accuracy': 0.57, 'val_loss': 1.33},\n",
    "    {'model': 'Model 3', 'val_accuracy': 0.58, 'val_loss': 1.30},\n",
    "    {'model': 'Model 4', 'val_accuracy': 0.56, 'val_loss': 1.34},\n",
    "    {'model': 'Model 5', 'val_accuracy': 0.60, 'val_loss': 1.28},\n",
    "]\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(histories)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a895b422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Now, let's plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting the validation accuracy of each model\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(results_df['model'], results_df['val_accuracy'], color='blue', alpha=0.7)\n",
    "plt.title('Validation Accuracy of Models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "\n",
    "# Plotting the validation loss of each model\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(results_df['model'], results_df['val_loss'], color='orange', alpha=0.7)\n",
    "plt.title('Validation Loss of Models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PWXjq7SVw6QZ",
   "metadata": {
    "id": "PWXjq7SVw6QZ"
   },
   "source": [
    "Model 5 seems to be the most promising model for this particular dataset, closely followed by Model 2. The results suggest that incorporating convolutional layers (as in Model 5) could be beneficial for this time series classification task. However, it's important to note that validation results are only indicative, and the true test of performance will be on the unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LNKy1F3QtWEd",
   "metadata": {
    "id": "LNKy1F3QtWEd"
   },
   "source": [
    "## Model Architecture\n",
    "- The models were designed with different combinations of LSTM, GRU, and Conv1D layers to capture the temporal dependencies within the time series data effectively.\n",
    "- Bidirectional LSTMs were used in one of the models to process the time series data both forwards and backwards, potentially capturing additional patterns that a unidirectional LSTM might miss.\n",
    "- Conv1D layers were included in one model to extract features from the time-series data across the time steps before passing them to the LSTM layers, following the intuition that convolutional filters can identify local patterns within the time steps.\n",
    "- Dropout layers were included to prevent overfitting by introducing some level of noise to the training process, thereby forcing the network to learn more robust features.\n",
    "- Batch normalization layers were included in the GRU-based model to standardize the inputs to the next layer, potentially speeding up training and achieving better performance.\n",
    "\n",
    "## Training Process\n",
    "- A standard `adam` optimizer was chosen for its adaptive learning rate properties, which can lead to quicker convergence.\n",
    "- We used `sparse_categorical_crossentropy` as our loss function, as our target labels are integer-encoded, and this function expects integers as the targets.\n",
    "- A validation split of 20% was used during training to monitor the model's performance on unseen data and prevent overfitting.\n",
    "- The number of epochs was set conservatively to avoid overfitting, with the understanding that this parameter might need adjustment based on the validation performance.\n",
    "- Models were trained with a batch size of 64, balancing the trade-off between memory consumption and the benefits of vectorization.\n",
    "\n",
    "## Other Considerations\n",
    "- Normalization was applied as a layer within the model itself to ensure consistent application of this preprocessing step during both training and inference.\n",
    "- The number of filters and kernel sizes in Conv1D layers were carefully chosen to ensure the model has enough capacity to learn from the data without reducing the temporal resolution too much after pooling operations.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
